You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
Loading checkpoint shards: 100%|████████████████████████████████████| 2/2 [00:00<00:00,  2.10it/s]
trainable params: 1,843,200 || all params: 3,756,466,176 || trainable%: 0.0491
  0%|                                                                    | 0/4750 [00:00<?, ?it/s]/home/jiyoon/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/jiyoon/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
  0%|                                                         | 3/4750 [01:15<33:47:53, 25.63s/it]Traceback (most recent call last):
  File "/home/jiyoon/LViton_GRPO/train.py", line 128, in <module>
    trainer.train()
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/trainer.py", line 3790, in training_step
    inputs = self._prepare_inputs(inputs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1258, in _prepare_inputs
    generation_batch = self._generate_and_score_completions(generation_batch)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1574, in _generate_and_score_completions
    prompt_completion_ids = unwrapped_model.generate(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/peft/peft_model.py", line 1973, in generate
    outputs = self.base_model.generate(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/generation/utils.py", line 2634, in generate
    result = self._sample(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/generation/utils.py", line 3618, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1493, in forward
    outputs = self.model(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1323, in forward
    outputs = self.language_model(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 914, in forward
    layer_outputs = decoder_layer(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 765, in forward
    hidden_states, self_attn_weights = self.self_attn(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 679, in forward
    query_states, key_states = apply_multimodal_rotary_pos_emb(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 611, in apply_multimodal_rotary_pos_emb
    q_embed = (q * cos) + (rotate_half(q) * sin)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 143, in rotate_half
    return torch.cat((-x2, x1), dim=-1)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/jiyoon/LViton_GRPO/train.py", line 128, in <module>
    trainer.train()
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2238, in train
    return inner_training_loop(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2582, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/trainer.py", line 3790, in training_step
    inputs = self._prepare_inputs(inputs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/trl/extras/profiling.py", line 98, in wrapper
    return func(self, *args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1258, in _prepare_inputs
    generation_batch = self._generate_and_score_completions(generation_batch)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/trl/trainer/grpo_trainer.py", line 1574, in _generate_and_score_completions
    prompt_completion_ids = unwrapped_model.generate(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/peft/peft_model.py", line 1973, in generate
    outputs = self.base_model.generate(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/generation/utils.py", line 2634, in generate
    result = self._sample(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/generation/utils.py", line 3618, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1493, in forward
    outputs = self.model(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1323, in forward
    outputs = self.language_model(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 914, in forward
    layer_outputs = decoder_layer(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 765, in forward
    hidden_states, self_attn_weights = self.self_attn(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 679, in forward
    query_states, key_states = apply_multimodal_rotary_pos_emb(
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 611, in apply_multimodal_rotary_pos_emb
    q_embed = (q * cos) + (rotate_half(q) * sin)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 143, in rotate_half
    return torch.cat((-x2, x1), dim=-1)
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7fe9eb50c1f0>
Traceback (most recent call last):
  File "/home/jiyoon/.local/lib/python3.10/site-packages/wandb/sdk/lib/service/service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/home/jiyoon/.local/lib/python3.10/site-packages/wandb/sdk/lib/service/service_connection.py", line 182, in teardown
    self._router.join()
  File "/home/jiyoon/.local/lib/python3.10/site-packages/wandb/sdk/interface/router.py", line 75, in join
    self._thread.join()
  File "/usr/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt:
